{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCV-YOLOv3tiny-pretrained",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NWB9WRVC1056",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Set up the environment"
      ]
    },
    {
      "metadata": {
        "id": "n89FWUvommQ5",
        "colab_type": "code",
        "outputId": "daa54e7c-f397-4c48-d0f3-9cacf725a898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "# Check python and CUDA version\n",
        "!python --version\n",
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.7\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Tue_Jun_12_23:07:04_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l6iVsmSsnGFR",
        "colab_type": "code",
        "outputId": "95964868-cf41-4c95-d23f-82d5d65a8c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "# Map your google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"drive/My Drive/app\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "car.jpeg\t  imagenet_class_index.json  run.mp4_yolo_out_py.avi\n",
            "cat.png\t\t  main.ipynb\t\t     test.ipynb\n",
            "dogs_and_cats\t  mnist_cnn.py\t\t     transferlearningUWB\n",
            "hymenoptera_data  outout.txt\t\t     uwb_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jX_EM1XeX7Aq",
        "colab_type": "code",
        "outputId": "bb5a50b0-11ca-4795-9ecf-418413029808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "cell_type": "code",
      "source": [
        "# Download pre-trained YOLOv3-tiny model\n",
        "# You can download other YOLO versions to test \n",
        "\n",
        "!wget https://pjreddie.com/media/files/yolov3-tiny.weights\n",
        "!wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg?raw=true -O ./yolov3-tiny.cfg\n",
        "!wget https://github.com/pjreddie/darknet/blob/master/data/coco.names?raw=true -O ./coco.names"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-25 20:02:09--  https://pjreddie.com/media/files/yolov3-tiny.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35434956 (34M) [application/octet-stream]\n",
            "Saving to: ‘yolov3-tiny.weights’\n",
            "\n",
            "yolov3-tiny.weights 100%[===================>]  33.79M  16.0MB/s    in 2.1s    \n",
            "\n",
            "2018-11-25 20:02:12 (16.0 MB/s) - ‘yolov3-tiny.weights’ saved [35434956/35434956]\n",
            "\n",
            "--2018-11-25 20:02:14--  https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/pjreddie/darknet/raw/master/cfg/yolov3-tiny.cfg [following]\n",
            "--2018-11-25 20:02:14--  https://github.com/pjreddie/darknet/raw/master/cfg/yolov3-tiny.cfg\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg [following]\n",
            "--2018-11-25 20:02:15--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1915 (1.9K) [text/plain]\n",
            "Saving to: ‘./yolov3-tiny.cfg’\n",
            "\n",
            "./yolov3-tiny.cfg   100%[===================>]   1.87K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-11-25 20:02:15 (186 MB/s) - ‘./yolov3-tiny.cfg’ saved [1915/1915]\n",
            "\n",
            "--2018-11-25 20:02:18--  https://github.com/pjreddie/darknet/blob/master/data/coco.names?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/pjreddie/darknet/raw/master/data/coco.names [following]\n",
            "--2018-11-25 20:02:19--  https://github.com/pjreddie/darknet/raw/master/data/coco.names\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names [following]\n",
            "--2018-11-25 20:02:19--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘./coco.names’\n",
            "\n",
            "./coco.names        100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2018-11-25 20:02:19 (60.9 MB/s) - ‘./coco.names’ saved [625/625]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZavEMAdu0Wp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize the parameters\n",
        "confThreshold = 0.5  #Confidence threshold\n",
        "nmsThreshold = 0.4   #Non-maximum suppression threshold\n",
        "inpWidth = 416       #Width of network's input image\n",
        "inpHeight = 416      #Height of network's input image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuypSPOcrjEZ",
        "colab_type": "code",
        "outputId": "cf25048d-e69c-41a5-aaa3-81ac940d404a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "# Load names of classes\n",
        "classesFile = \"coco.names\";\n",
        "classes = None\n",
        "i = 0\n",
        "print(\"Class names:\")\n",
        "with open(classesFile, 'rt') as f:\n",
        "    classes = f.read().rstrip('\\n').split('\\n')\n",
        "    print(classes)\n",
        " \n",
        "# Give the configuration and weight files for the model and load the network using them.\n",
        "modelConfiguration = \"yolov3.cfg\";\n",
        "modelWeights = \"yolov3.weights\";\n",
        " \n",
        "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
        "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "print(\"Layer list:\")\n",
        "print(net.getLayerNames())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class names:\n",
            "1 :  ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
            "Layer list:\n",
            "['conv_0', 'bn_0', 'relu_0', 'conv_1', 'bn_1', 'relu_1', 'conv_2', 'bn_2', 'relu_2', 'conv_3', 'bn_3', 'relu_3', 'shortcut_4', 'conv_5', 'bn_5', 'relu_5', 'conv_6', 'bn_6', 'relu_6', 'conv_7', 'bn_7', 'relu_7', 'shortcut_8', 'conv_9', 'bn_9', 'relu_9', 'conv_10', 'bn_10', 'relu_10', 'shortcut_11', 'conv_12', 'bn_12', 'relu_12', 'conv_13', 'bn_13', 'relu_13', 'conv_14', 'bn_14', 'relu_14', 'shortcut_15', 'conv_16', 'bn_16', 'relu_16', 'conv_17', 'bn_17', 'relu_17', 'shortcut_18', 'conv_19', 'bn_19', 'relu_19', 'conv_20', 'bn_20', 'relu_20', 'shortcut_21', 'conv_22', 'bn_22', 'relu_22', 'conv_23', 'bn_23', 'relu_23', 'shortcut_24', 'conv_25', 'bn_25', 'relu_25', 'conv_26', 'bn_26', 'relu_26', 'shortcut_27', 'conv_28', 'bn_28', 'relu_28', 'conv_29', 'bn_29', 'relu_29', 'shortcut_30', 'conv_31', 'bn_31', 'relu_31', 'conv_32', 'bn_32', 'relu_32', 'shortcut_33', 'conv_34', 'bn_34', 'relu_34', 'conv_35', 'bn_35', 'relu_35', 'shortcut_36', 'conv_37', 'bn_37', 'relu_37', 'conv_38', 'bn_38', 'relu_38', 'conv_39', 'bn_39', 'relu_39', 'shortcut_40', 'conv_41', 'bn_41', 'relu_41', 'conv_42', 'bn_42', 'relu_42', 'shortcut_43', 'conv_44', 'bn_44', 'relu_44', 'conv_45', 'bn_45', 'relu_45', 'shortcut_46', 'conv_47', 'bn_47', 'relu_47', 'conv_48', 'bn_48', 'relu_48', 'shortcut_49', 'conv_50', 'bn_50', 'relu_50', 'conv_51', 'bn_51', 'relu_51', 'shortcut_52', 'conv_53', 'bn_53', 'relu_53', 'conv_54', 'bn_54', 'relu_54', 'shortcut_55', 'conv_56', 'bn_56', 'relu_56', 'conv_57', 'bn_57', 'relu_57', 'shortcut_58', 'conv_59', 'bn_59', 'relu_59', 'conv_60', 'bn_60', 'relu_60', 'shortcut_61', 'conv_62', 'bn_62', 'relu_62', 'conv_63', 'bn_63', 'relu_63', 'conv_64', 'bn_64', 'relu_64', 'shortcut_65', 'conv_66', 'bn_66', 'relu_66', 'conv_67', 'bn_67', 'relu_67', 'shortcut_68', 'conv_69', 'bn_69', 'relu_69', 'conv_70', 'bn_70', 'relu_70', 'shortcut_71', 'conv_72', 'bn_72', 'relu_72', 'conv_73', 'bn_73', 'relu_73', 'shortcut_74', 'conv_75', 'bn_75', 'relu_75', 'conv_76', 'bn_76', 'relu_76', 'conv_77', 'bn_77', 'relu_77', 'conv_78', 'bn_78', 'relu_78', 'conv_79', 'bn_79', 'relu_79', 'conv_80', 'bn_80', 'relu_80', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'relu_84', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'relu_87', 'conv_88', 'bn_88', 'relu_88', 'conv_89', 'bn_89', 'relu_89', 'conv_90', 'bn_90', 'relu_90', 'conv_91', 'bn_91', 'relu_91', 'conv_92', 'bn_92', 'relu_92', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'relu_96', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'relu_99', 'conv_100', 'bn_100', 'relu_100', 'conv_101', 'bn_101', 'relu_101', 'conv_102', 'bn_102', 'relu_102', 'conv_103', 'bn_103', 'relu_103', 'conv_104', 'bn_104', 'relu_104', 'conv_105', 'permute_106', 'yolo_106']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DT6Z_W4i2ilg",
        "colab_type": "code",
        "outputId": "08699bba-3b91-4522-b648-e0730093021e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# Input video file\n",
        "# You can change the input video from your own google drive\n",
        "cap = cv.VideoCapture('drive/My Drive/app/street.mp4')\n",
        "length = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "print('Total number of frames in the input video: ',length )\n",
        "\n",
        "\n",
        "# Output video file with bounding boxes surrounding objects\n",
        "outputFile = \"street_yolo.avi\"\n",
        "vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc('M','J','P','G'), 30, (round(cap.get(cv.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
        "print('Output will be written to: ', outputFile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of frames in the input video:  150\n",
            "Output will be written to:  street_yolo.avi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Assn4qVl2GPR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Some helper functions for post processing the output from darknet\n",
        "\n",
        "# Get the names of the output layers\n",
        "def getOutputsNames(net):\n",
        "    # Get the names of all the layers in the network\n",
        "    layersNames = net.getLayerNames()\n",
        "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
        "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
        "def postprocess(frame, outs):\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        " \n",
        "    classIds = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    # Scan through all the bounding boxes output from the network and keep only the\n",
        "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
        "    classIds = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if confidence > confThreshold:\n",
        "                center_x = int(detection[0] * frameWidth)\n",
        "                center_y = int(detection[1] * frameHeight)\n",
        "                width = int(detection[2] * frameWidth)\n",
        "                height = int(detection[3] * frameHeight)\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                classIds.append(classId)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([left, top, width, height])\n",
        " \n",
        "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
        "    # lower confidences.\n",
        "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        left = box[0]\n",
        "        top = box[1]\n",
        "        width = box[2]\n",
        "        height = box[3]\n",
        "        drawPred(classIds[i], confidences[i], left, top, left + width, top + height)\n",
        "  \n",
        "# Draw the predicted bounding box\n",
        "def drawPred(classId, conf, left, top, right, bottom):\n",
        "    # Draw a bounding box.\n",
        "    cv.rectangle(frame, (left, top), (right, bottom), (0, 0, 255))\n",
        "     \n",
        "    label = '%.2f' % conf\n",
        "         \n",
        "    # Get the label for the class name and its confidence\n",
        "    if classes:\n",
        "        assert(classId < len(classes))\n",
        "        label = '%s:%s' % (classes[classId], label)\n",
        " \n",
        "    #Display the label at the top of the bounding box\n",
        "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "    top = max(top, labelSize[1])\n",
        "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3J_UewQkzb3i",
        "colab_type": "code",
        "outputId": "edb9962a-0db2-46bb-da5f-d5fa84610042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2549
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "i = 0\n",
        "while (1):\n",
        "    # get frame from the video\n",
        "    hasFrame, frame = cap.read()\n",
        "     \n",
        "    # Stop the program if reached end of video\n",
        "    if not hasFrame:\n",
        "        print(\"Done processing !!!\")\n",
        "        print(\"Output file is stored as \", outputFile)\n",
        "        break\n",
        "\n",
        "    i = i+1\n",
        "    print('Frame #',i)\n",
        "\n",
        "\n",
        "    # Create a 4D blob from a frame.\n",
        "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
        " \n",
        "    # Sets the input to the network\n",
        "    net.setInput(blob)\n",
        " \n",
        "    # Runs the forward pass to get output of the output layers\n",
        "    outs = net.forward(getOutputsNames(net))\n",
        " \n",
        "    # Remove the bounding boxes with low confidence\n",
        "    postprocess(frame, outs)\n",
        " \n",
        "    # Put efficiency information. The function getPerfProfile returns the \n",
        "    # overall time for inference(t) and the timings for each of the layers(in layersTimes)\n",
        "    t, _ = net.getPerfProfile()\n",
        "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
        "    cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
        " \n",
        "    vid_writer.write(frame.astype(np.uint8));\n",
        "\n",
        "vid_writer.release()\n",
        "cap.release()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frame # 1\n",
            "Frame # 2\n",
            "Frame # 3\n",
            "Frame # 4\n",
            "Frame # 5\n",
            "Frame # 6\n",
            "Frame # 7\n",
            "Frame # 8\n",
            "Frame # 9\n",
            "Frame # 10\n",
            "Frame # 11\n",
            "Frame # 12\n",
            "Frame # 13\n",
            "Frame # 14\n",
            "Frame # 15\n",
            "Frame # 16\n",
            "Frame # 17\n",
            "Frame # 18\n",
            "Frame # 19\n",
            "Frame # 20\n",
            "Frame # 21\n",
            "Frame # 22\n",
            "Frame # 23\n",
            "Frame # 24\n",
            "Frame # 25\n",
            "Frame # 26\n",
            "Frame # 27\n",
            "Frame # 28\n",
            "Frame # 29\n",
            "Frame # 30\n",
            "Frame # 31\n",
            "Frame # 32\n",
            "Frame # 33\n",
            "Frame # 34\n",
            "Frame # 35\n",
            "Frame # 36\n",
            "Frame # 37\n",
            "Frame # 38\n",
            "Frame # 39\n",
            "Frame # 40\n",
            "Frame # 41\n",
            "Frame # 42\n",
            "Frame # 43\n",
            "Frame # 44\n",
            "Frame # 45\n",
            "Frame # 46\n",
            "Frame # 47\n",
            "Frame # 48\n",
            "Frame # 49\n",
            "Frame # 50\n",
            "Frame # 51\n",
            "Frame # 52\n",
            "Frame # 53\n",
            "Frame # 54\n",
            "Frame # 55\n",
            "Frame # 56\n",
            "Frame # 57\n",
            "Frame # 58\n",
            "Frame # 59\n",
            "Frame # 60\n",
            "Frame # 61\n",
            "Frame # 62\n",
            "Frame # 63\n",
            "Frame # 64\n",
            "Frame # 65\n",
            "Frame # 66\n",
            "Frame # 67\n",
            "Frame # 68\n",
            "Frame # 69\n",
            "Frame # 70\n",
            "Frame # 71\n",
            "Frame # 72\n",
            "Frame # 73\n",
            "Frame # 74\n",
            "Frame # 75\n",
            "Frame # 76\n",
            "Frame # 77\n",
            "Frame # 78\n",
            "Frame # 79\n",
            "Frame # 80\n",
            "Frame # 81\n",
            "Frame # 82\n",
            "Frame # 83\n",
            "Frame # 84\n",
            "Frame # 85\n",
            "Frame # 86\n",
            "Frame # 87\n",
            "Frame # 88\n",
            "Frame # 89\n",
            "Frame # 90\n",
            "Frame # 91\n",
            "Frame # 92\n",
            "Frame # 93\n",
            "Frame # 94\n",
            "Frame # 95\n",
            "Frame # 96\n",
            "Frame # 97\n",
            "Frame # 98\n",
            "Frame # 99\n",
            "Frame # 100\n",
            "Frame # 101\n",
            "Frame # 102\n",
            "Frame # 103\n",
            "Frame # 104\n",
            "Frame # 105\n",
            "Frame # 106\n",
            "Frame # 107\n",
            "Frame # 108\n",
            "Frame # 109\n",
            "Frame # 110\n",
            "Frame # 111\n",
            "Frame # 112\n",
            "Frame # 113\n",
            "Frame # 114\n",
            "Frame # 115\n",
            "Frame # 116\n",
            "Frame # 117\n",
            "Frame # 118\n",
            "Frame # 119\n",
            "Frame # 120\n",
            "Frame # 121\n",
            "Frame # 122\n",
            "Frame # 123\n",
            "Frame # 124\n",
            "Frame # 125\n",
            "Frame # 126\n",
            "Frame # 127\n",
            "Frame # 128\n",
            "Frame # 129\n",
            "Frame # 130\n",
            "Frame # 131\n",
            "Frame # 132\n",
            "Frame # 133\n",
            "Frame # 134\n",
            "Frame # 135\n",
            "Frame # 136\n",
            "Frame # 137\n",
            "Frame # 138\n",
            "Frame # 139\n",
            "Frame # 140\n",
            "Frame # 141\n",
            "Frame # 142\n",
            "Frame # 143\n",
            "Frame # 144\n",
            "Frame # 145\n",
            "Frame # 146\n",
            "Frame # 147\n",
            "Frame # 148\n",
            "Frame # 149\n",
            "Frame # 150\n",
            "Done processing !!!\n",
            "Output file is stored as  street_yolo.avi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9k3YFuKTzdVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copy the output file to google drive\n",
        "\n",
        "!cp street_yolo.avi drive/My\\ Drive/app/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
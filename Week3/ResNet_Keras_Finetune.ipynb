{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet_Keras_Finetune.ipynb","version":"0.3.2","provenance":[{"file_id":"1iVChsQa7dAJych6gciq21QZB5tEVlzIw","timestamp":1542228128297},{"file_id":"1MoE5CvDz5pOOoJkmWRstqqb1JzD46Lmt","timestamp":1541570487368}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"NWB9WRVC1056","colab_type":"text"},"cell_type":"markdown","source":["1. Set up the environment"]},{"metadata":{"id":"n89FWUvommQ5","colab_type":"code","outputId":"ecd9b990-3ab3-40bc-8b63-c36b430720f9","executionInfo":{"status":"ok","timestamp":1542225818916,"user_tz":-600,"elapsed":7557,"user":{"displayName":"Kien Nguyen Thanh","photoUrl":"","userId":"02481478048304121936"}},"colab":{"base_uri":"https://localhost:8080/","height":133}},"cell_type":"code","source":["# Check python and CUDA version\n","!python --version\n","!nvcc --version"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Python 3.6.6\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Tue_Jun_12_23:07:04_CDT_2018\n","Cuda compilation tools, release 9.2, V9.2.148\n"],"name":"stdout"}]},{"metadata":{"id":"l6iVsmSsnGFR","colab_type":"code","colab":{}},"cell_type":"code","source":["# Map your google drive \n","from google.colab import drive\n","drive.mount('/content/drive/')\n","!ls \"drive/My Drive\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vuecM9uH4Ujk","colab_type":"code","outputId":"b36a15f1-3d3b-49fd-ff70-22c2d890ffe7","executionInfo":{"status":"ok","timestamp":1542225864937,"user_tz":-600,"elapsed":3935,"user":{"displayName":"Kien Nguyen Thanh","photoUrl":"","userId":"02481478048304121936"}},"colab":{"base_uri":"https://localhost:8080/","height":99}},"cell_type":"code","source":["!ls \"drive/My Drive/app\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["car.jpeg\t  imagenet_class_index.json  outout.txt    transferlearningUWB\n","cat.png\t\t  main.ipynb\t\t     ResNet.ipynb  uwb_ID\n","hymenoptera_data  mnist_cnn.py\t\t     test.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"ZavEMAdu0Wp2","colab_type":"code","outputId":"22016eef-319f-446e-9dee-54d1d427b928","executionInfo":{"status":"ok","timestamp":1542225889360,"user_tz":-600,"elapsed":6442,"user":{"displayName":"Kien Nguyen Thanh","photoUrl":"","userId":"02481478048304121936"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"cell_type":"code","source":["!pip install -q keras\n","# Check keras installation\n","!pip show keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Name: Keras\n","Version: 2.2.4\n","Summary: Deep Learning for humans\n","Home-page: https://github.com/keras-team/keras\n","Author: Francois Chollet\n","Author-email: francois.chollet@gmail.com\n","License: MIT\n","Location: /usr/local/lib/python3.6/dist-packages\n","Requires: six, scipy, keras-applications, numpy, pyyaml, keras-preprocessing, h5py\n","Required-by: \n"],"name":"stdout"}]},{"metadata":{"id":"ZuypSPOcrjEZ","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications.resnet50 import ResNet50\n","\n","model = ResNet50(weights='imagenet')\n","print(model.summary())\n","\n","# Check the list of pre-trained models here\n","# https://keras.io/applications/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WJ98fQucApDY","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","import sys\n","import os\n","from collections import defaultdict\n","import numpy as np\n","import scipy.misc\n","\n","\n","def preprocess_input(x0):\n","    x = x0 / 255.\n","    x -= 0.5\n","    x *= 2.\n","    return x\n","\n","\n","def reverse_preprocess_input(x0):\n","    x = x0 / 2.0\n","    x += 0.5\n","    x *= 255.\n","    return x\n","\n","\n","def dataset(base_dir, n):\n","    d = defaultdict(list)\n","    for root, subdirs, files in os.walk(base_dir):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","            assert file_path.startswith(base_dir)\n","            suffix = file_path[len(base_dir):]\n","            suffix = suffix.lstrip(\"/\")\n","            label = suffix.split(\"/\")[0]\n","            d[label].append(file_path)\n","\n","    tags = sorted(d.keys())\n","\n","    processed_image_count = 0\n","    useful_image_count = 0\n","\n","    X = []\n","    y = []\n","\n","    for class_index, class_name in enumerate(tags):\n","        filenames = d[class_name]\n","        for filename in filenames:\n","            processed_image_count += 1\n","            img = scipy.misc.imread(filename)\n","            height, width, chan = img.shape\n","            assert chan == 3\n","            aspect_ratio = float(max((height, width))) / min((height, width))\n","            if aspect_ratio > 2:\n","                continue\n","            # We pick the largest center square.\n","            centery = height // 2\n","            centerx = width // 2\n","            radius = min((centerx, centery))\n","            img = img[centery-radius:centery+radius, centerx-radius:centerx+radius]\n","            img = scipy.misc.imresize(img, size=(n, n), interp='bilinear')\n","            X.append(img)\n","            y.append(class_index)\n","            useful_image_count += 1\n","    print(\"processed %d, used %d\" % (processed_image_count, useful_image_count))\n","\n","    X = np.array(X).astype(np.float32)\n","    X = X.transpose((0, 3, 1, 2))\n","    X = preprocess_input(X)\n","    y = np.array(y)\n","\n","    perm = np.random.permutation(len(y))\n","    X = X[perm]\n","    y = y[perm]\n","\n","    print(\"classes:\")\n","    for class_index, class_name in enumerate(tags):\n","        print(class_name, sum(y==class_index))\n","    print\n","\n","    return X, y, tags\n","  \n","# create the base pre-trained model\n","def build_model(nb_classes):\n","    base_model = InceptionV3(weights='imagenet', include_top=False)\n","\n","    # add a global spatial average pooling layer\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    # let's add a fully-connected layer\n","    x = Dense(1024, activation='relu')(x)\n","    # and a logistic layer\n","    predictions = Dense(nb_classes, activation='softmax')(x)\n","\n","    # this is the model we will train\n","    model = Model(input=base_model.input, output=predictions)\n","\n","    # first: train only the top layers (which were randomly initialized)\n","    # i.e. freeze all convolutional InceptionV3 layers\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    # compile the model (should be done *after* setting layers to non-trainable)\n","    print(\"starting model compile\")\n","    compile(model)\n","    print(\"model compile done\")\n","    return model\n","\n","\n","def save(model, tags, prefix):\n","    model.save_weights(prefix+\".h5\")\n","    # serialize model to JSON\n","    model_json = model.to_json()\n","    with open(prefix+\".json\", \"w\") as json_file:\n","        json_file.write(model_json)\n","    with open(prefix+\"-labels.json\", \"w\") as json_file:\n","        json.dump(tags, json_file)\n","\n","\n","def load(prefix):\n","    # load json and create model\n","    with open(prefix+\".json\") as json_file:\n","        model_json = json_file.read()\n","    model = model_from_json(model_json)\n","    # load weights into new model\n","    model.load_weights(prefix+\".h5\")\n","    with open(prefix+\"-labels.json\") as json_file:\n","        tags = json.load(json_file)\n","    return model, tags\n","\n","def compile(model):\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DT6Z_W4i2ilg","colab_type":"code","colab":{}},"cell_type":"code","source":["# 1. Finetune a pre-trained model on our own dataset\n","\n","import sys\n","import json\n","\n","import numpy as np\n","from collections import defaultdict\n","\n","# It's very important to put this import before keras,\n","# as explained here: Loading tensorflow before scipy.misc seems to cause imread to fail #1541\n","# https://github.com/tensorflow/tensorflow/issues/1541\n","import scipy.misc\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import SGD\n","from keras import backend as K\n","from keras.utils import np_utils\n","\n","\n","np.random.seed(1337)\n","\n","n = 224\n","batch_size = 128\n","nb_epoch = 20\n","nb_phase_two_epoch = 20\n","# Use heavy augmentation if you plan to use the model with the\n","# accompanying webcam.py app, because webcam data is quite different from photos.\n","heavy_augmentation = True\n","\n","train_directory = 'drive/My Drive/app/hymenoptera_data/train'\n","test_directory = 'drive/My Drive/app/hymenoptera_data/test'\n","model_file_prefix = ResNet50(weights='imagenet')\n","\n","print(\"loading dataset\")\n","\n","X_train, y_train, tags = dataset(train_directory, n)\n","nb_classes = len(tags)\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","\n","\n","X_test, y_test, tags = dataset(test_directory, n)\n","nb_classes = len(tags)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)\n","\n","\n","\n","if heavy_augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,\n","        samplewise_center=False,\n","        featurewise_std_normalization=False,\n","        samplewise_std_normalization=False,\n","        zca_whitening=False,\n","        rotation_range=45,\n","        width_shift_range=0.25,\n","        height_shift_range=0.25,\n","        horizontal_flip=True,\n","        vertical_flip=False,\n","        zoom_range=0.5,\n","        channel_shift_range=0.5,\n","        fill_mode='nearest')\n","else:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,\n","        samplewise_center=False,\n","        featurewise_std_normalization=False,\n","        samplewise_std_normalization=False,\n","        zca_whitening=False,\n","        rotation_range=0,\n","        width_shift_range=0.125,\n","        height_shift_range=0.125,\n","        horizontal_flip=True,\n","        vertical_flip=False,\n","        fill_mode='nearest')\n","\n","datagen.fit(X_train)\n","\n","def evaluate(model, vis_filename=None):\n","    Y_pred = model.predict(X_test, batch_size=batch_size)\n","    y_pred = np.argmax(Y_pred, axis=1)\n","\n","    accuracy = float(np.sum(y_test==y_pred)) / len(y_test)\n","    print(\"accuracy:%f\", accuracy)\n","    \n","    confusion = np.zeros((nb_classes, nb_classes), dtype=np.int32)\n","    for (predicted_index, actual_index, image) in zip(y_pred, y_test, X_test):\n","        confusion[predicted_index, actual_index] += 1\n","    \n","    print(\"rows are predicted classes, columns are actual classes\")\n","    for predicted_index, predicted_tag in enumerate(tags):\n","        print(predicted_tag[:7]),\n","        for actual_index, actual_tag in enumerate(tags):\n","            print(\"\\t%d\" % confusion[predicted_index, actual_index]),\n","        print\n","    if vis_filename is not None:\n","        bucket_size = 10\n","        image_size = n // 4 # right now that's 56\n","        vis_image_size = nb_classes * image_size * bucket_size\n","        vis_image = 255 * np.ones((vis_image_size, vis_image_size, 3), dtype='uint8')\n","        example_counts = defaultdict(int)\n","        for (predicted_tag, actual_tag, normalized_image) in zip(y_pred, y_test, X_test):\n","            example_count = example_counts[(predicted_tag, actual_tag)]\n","            if example_count >= bucket_size**2:\n","                continue\n","            image = reverse_preprocess_input(normalized_image)\n","            image = image.transpose((1, 2, 0))\n","            image = scipy.misc.imresize(image, (image_size, image_size)).astype(np.uint8)\n","            tilepos_x = bucket_size * predicted_tag\n","            tilepos_y = bucket_size * actual_tag\n","            tilepos_x += example_count % bucket_size\n","            tilepos_y += example_count // bucket_size\n","            pos_x, pos_y = tilepos_x * image_size, tilepos_y * image_size\n","            vis_image[pos_y:pos_y+image_size, pos_x:pos_x+image_size, :] = image\n","            example_counts[(predicted_tag, actual_tag)] += 1\n","        vis_image[::image_size * bucket_size, :] = 0\n","        vis_image[:, ::image_size * bucket_size] = 0\n","        scipy.misc.imsave(vis_filename, vis_image)\n","\n","print(\"loading original inception model\")\n","\n","model = build_model(nb_classes)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n","\n","# train the model on the new data for a few epochs\n","\n","print(\"training the newly added dense layers\")\n","\n","model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),\n","            samples_per_epoch=X_train.shape[0],\n","            nb_epoch=nb_epoch,\n","            validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size),\n","            nb_val_samples=X_test.shape[0],\n","            )\n","\n","evaluate(model, \"000.png\")\n","\n","save(model, tags, model_file_prefix)\n","\n","# at this point, the top layers are well trained and we can start fine-tuning\n","# convolutional layers from inception V3. We will freeze the bottom N layers\n","# and train the remaining top layers.\n","\n","# we chose to train the top 2 inception blocks, i.e. we will freeze\n","# the first 172 layers and unfreeze the rest:\n","for layer in model.layers[:172]:\n","   layer.trainable = False\n","for layer in model.layers[172:]:\n","   layer.trainable = True\n","\n","# we need to recompile the model for these modifications to take effect\n","# we use SGD with a low learning rate\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n","\n","# we train our model again (this time fine-tuning the top 2 inception blocks\n","# alongside the top Dense layers\n","\n","print(\"fine-tuning top 2 inception blocks alongside the top dense layers\")\n","\n","for i in range(1,11):\n","    print(\"mega-epoch %d/10\" % i)\n","    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),\n","            samples_per_epoch=X_train.shape[0],\n","            nb_epoch=nb_phase_two_epoch,\n","            validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size),\n","            nb_val_samples=X_test.shape[0],\n","            )\n","\n","    evaluate(model, str(i).zfill(3)+\".png\")\n","\n","    save(model, tags, model_file_prefix)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Assn4qVl2GPR","colab_type":"code","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RQ6B4Qta2KB4","colab_type":"text"},"cell_type":"markdown","source":["Keras code of Resnet50\n","https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n"]}]}